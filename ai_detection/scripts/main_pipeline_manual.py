"""
å®Œæ•´çš„äº¤é€šè¿è§„æ£€æµ‹ç®¡é“ - æ‰‹åŠ¨æ§åˆ¶ç‰ˆæœ¬
é€‚ç”¨äºè‡ªåˆ¶æµ‹è¯•è§†é¢‘ï¼ˆæ— ä¿¡å·ç¯ã€æ— è½¦ç‰Œï¼‰
```python main_pipeline_manual.py --video YOUR_VIDEO.mp4 --rotation 90```bash**å¿«é€Ÿè§£å†³**ï¼š- **æ¨èåœ¨é‡‡é›†æ•°æ®æ—¶ä¿è¯è§†è§’æ­£å¸¸**- **ä½¿ç”¨ `--rotation` å‚æ•°å³å¯è§£å†³**- **90åº¦æ—‹è½¬å¯¼è‡´æ£€æµ‹å¤±æ•ˆæ˜¯æ­£å¸¸ç°è±¡**## æ€»ç»“---   - ä¸¥é‡æ¨¡ç³Šï¼Ÿ   - è½¦è¾†å¤ªå°ï¼Ÿ   - åˆ†è¾¨ç‡å¤ªä½ï¼Ÿ3. **æ£€æŸ¥è§†é¢‘è´¨é‡**   ```   # ç½®ä¿¡åº¦å·²é»˜è®¤è®¾ä¸º0.25   python main_pipeline_manual.py --video data/test.mp4 --rotation 90   # é™ä½ç½®ä¿¡åº¦   ```bash2. **æ£€æŸ¥ç½®ä¿¡åº¦é˜ˆå€¼**   ```   python -c "import cv2; cap=cv2.VideoCapture('data/test.mp4'); ret,f=cap.read(); cv2.imwrite('frame.jpg',cv2.rotate(f,cv2.ROTATE_90_CLOCKWISE)); print('å·²ä¿å­˜frame.jpgï¼Œæ£€æŸ¥è½¦è¾†æ–¹å‘')"   # æŸ¥çœ‹æ—‹è½¬åçš„è§†é¢‘   ```bash1. **ç¡®è®¤æ—‹è½¬è§’åº¦æ­£ç¡®**### é—®é¢˜ï¼šæ—‹è½¬åè¿˜æ˜¯æ£€æµ‹ä¸åˆ°## ğŸ› æ•…éšœæ’æŸ¥---```done    python main_pipeline_manual.py --video "$video"for video in fixed_*.mp4; do# å†æ‰¹é‡æ£€æµ‹done    python Utility/video_rotator.py --input "$video" --output "fixed_$(basename $video)" --angle 90for video in data/*.mp4; do# å…ˆæ‰¹é‡æ—‹è½¬æ‰€æœ‰è§†é¢‘```bash### åœºæ™¯3ï¼šæ‰¹é‡å¤„ç†- é¿å…å€¾æ–œ- æ°´å¹³å®‰è£…ç¡®ä¿æ‘„åƒå¤´å®‰è£…è§’åº¦æ­£ç¡®ï¼š### åœºæ™¯2ï¼šç›‘æ§æ‘„åƒå¤´```python main_pipeline_manual.py --video data/phone.mp4 --rotation -90# æ‰‹æœºç«–å± â†’ éœ€è¦æ—‹è½¬```bashæ‰‹æœºç«–å±æ‹æ‘„ä¼šå¯¼è‡´90åº¦æ—‹è½¬ï¼š### åœºæ™¯1ï¼šæ‰‹æœºæ‹æ‘„çš„è§†é¢‘## ğŸ’¡ å®é™…åº”ç”¨å»ºè®®---- å¦‚æœè§†é¢‘æ—‹è½¬äº†ï¼Œç”¨è½¯ä»¶æ—‹è½¬å›æ¥ï¼ˆæˆæœ¬ä½ã€æ•ˆæœå¥½ï¼‰- åœ¨æ•°æ®é‡‡é›†æ—¶ä¿è¯è§†é¢‘æ˜¯æ­£å¸¸è§†è§’**æ›´å¥½çš„æ–¹æ¡ˆ**ï¼š3. é€šç”¨æ€§å·®ï¼ˆåªé€‚ç”¨äºç‰¹å®šè§†è§’ï¼‰2. è®­ç»ƒæˆæœ¬é«˜ï¼ˆæ—¶é—´ã€ç®—åŠ›ï¼‰1. éœ€è¦æ”¶é›†å¤§é‡æ—‹è½¬è§†è§’çš„è½¦è¾†æ•°æ®**å¯ä»¥ï¼Œä½†ä¸æ¨è**ï¼š### èƒ½å¦è®­ç»ƒè¯†åˆ«æ—‹è½¬è½¦è¾†çš„æ¨¡å‹ï¼Ÿ   - ç«–ç›´ç›®æ ‡æ— æ³•åŒ¹é…é¢„è®¾anchor   - YOLOv8çš„anchorè®¾è®¡é’ˆå¯¹æ°´å¹³ç›®æ ‡3. **Anchor Boxé—®é¢˜**   - æ¨¡å‹ä¼šè¯¯åˆ¤ä¸ºå…¶ä»–ç‰©ä½“   - æ—‹è½¬90åº¦ï¼šé«˜ > å®½ (å¦‚ 100x200åƒç´ )   - æ°´å¹³è½¦è¾†ï¼šå®½ > é«˜ (å¦‚ 200x100åƒç´ )2. **ç‰¹å¾ä¸åŒ¹é…**   - æ¨¡å‹å­¦ä¹ çš„ç‰¹å¾ï¼šè½¦å¤´ã€è½¦å°¾ã€è½®å­çš„**æ°´å¹³æ’åˆ—**æ¨¡å¼   - COCOæ•°æ®é›†ï¼š99%çš„è½¦è¾†éƒ½æ˜¯æ°´å¹³æ–¹å‘1. **è®­ç»ƒæ•°æ®åå·®**### ä¸ºä»€ä¹ˆä¸èƒ½ç›´æ¥è¯†åˆ«æ—‹è½¬çš„è½¦è¾†ï¼Ÿ## ğŸ”§ æŠ€æœ¯ç»†èŠ‚---**ç»“è®º**ï¼šæ—‹è½¬è¶…è¿‡30åº¦å°±ä¼šä¸¥é‡å½±å“æ£€æµ‹ï¼Œ**å¿…é¡»å…ˆæ—‹è½¬å›æ­£å¸¸è§†è§’**ã€‚| 180Â° | 20-30% | ä¸¥é‡å¤±æ•ˆ || 90Â° | 5-10% | å‡ ä¹å¤±æ•ˆ || Â±30Â° | 60-70% | âš ï¸ æ˜æ˜¾ä¸‹é™ || Â±15Â° | 85-90% | å¯æ¥å— || 0Â° (æ­£å¸¸) | 95%+ | æœ€ä½³ ||---------|-----------|------|| æ—‹è½¬è§’åº¦ | è½¦è¾†æ£€æµ‹ç‡ | è¯´æ˜ |## æ—‹è½¬å¯¹æ£€æµ‹çš„å½±å“---```python main_pipeline_manual.py --video data/test.mp4 --rotation -90  # é€†æ—¶é’ˆ90Â°python main_pipeline_manual.py --video data/test.mp4 --rotation 90   # é¡ºæ—¶é’ˆ90Â°python main_pipeline_manual.py --video data/test.mp4 --rotation 0    # ä¸æ—‹è½¬# è¯•è¯•ä¸åŒè§’åº¦ï¼Œçœ‹å“ªä¸ªæ£€æµ‹æ•ˆæœå¥½```bash### æµ‹è¯•æ³•3. å¦‚æœæ˜¯**ç«–å‘**è¡Œé©¶ï¼ˆâ†‘ â†“æ–¹å‘ï¼‰ï¼Œéœ€è¦æ—‹è½¬2. è½¦è¾†åº”è¯¥æ˜¯**æ¨ªå‘**è¡Œé©¶ï¼ˆâ† â†’æ–¹å‘ï¼‰1. æ‰“å¼€è§†é¢‘çœ‹ä¸€çœ¼### è§†è§‰åˆ¤æ–­æ³•## ğŸ¯ å¦‚ä½•åˆ¤æ–­éœ€è¦æ—‹è½¬å¤šå°‘åº¦ï¼Ÿ---- å¯ç”¨äºå…¶ä»–ç”¨é€”- é¿å…é‡å¤æ—‹è½¬- ä¿å­˜ä¿®æ­£åçš„è§†é¢‘**ä¼˜ç‚¹**ï¼š- `270`ï¼šé¡ºæ—¶é’ˆæ—‹è½¬270åº¦ï¼ˆ= é€†æ—¶é’ˆ90åº¦ï¼‰- `180`ï¼šç¿»è½¬180åº¦- `-90`ï¼šé€†æ—¶é’ˆæ—‹è½¬90åº¦  - `90`ï¼šé¡ºæ—¶é’ˆæ—‹è½¬90åº¦**æ—‹è½¬è§’åº¦è¯´æ˜**ï¼š```python main_pipeline_manual.py --video data/fixed.mp4# æ­¥éª¤2ï¼šç”¨æ—‹è½¬åçš„è§†é¢‘æ£€æµ‹python Utility/video_rotator.py --input data/rotated.mp4 --output data/fixed.mp4 --angle 90# æ­¥éª¤1ï¼šæ—‹è½¬è§†é¢‘```bash**é€‚ç”¨åœºæ™¯**ï¼šéœ€è¦ä¿å­˜æ—‹è½¬åçš„è§†é¢‘ï¼Œæˆ–å¤šæ¬¡ä½¿ç”¨### æ–¹æ¡ˆ2ï¼šé¢„å¤„ç†è§†é¢‘ï¼ˆç¦»çº¿å¤„ç†ï¼‰---- ç®€å•æ–¹ä¾¿- å®æ—¶å¤„ç†- ä¸éœ€è¦é¢„å¤„ç†è§†é¢‘**ä¼˜ç‚¹**ï¼š4. è¾“å‡ºç»“æœ3. ç”¨æ­£å¸¸è§†è§’æ£€æµ‹è½¦è¾†2. è‡ªåŠ¨æ—‹è½¬å›æ­£å¸¸è§†è§’1. è¯»å–æ¯ä¸€å¸§**å·¥ä½œåŸç†**ï¼š```python main_pipeline_manual.py --video data/rotated.mp4 --rotation 180# è§†é¢‘å€’ç½®180åº¦python main_pipeline_manual.py --video data/rotated.mp4 --rotation -90# è§†é¢‘è¢«é¡ºæ—¶é’ˆæ—‹è½¬äº†90åº¦ï¼Œéœ€è¦é€†æ—¶é’ˆæ—‹è½¬å›æ¥  python main_pipeline_manual.py --video data/rotated.mp4 --rotation 90# è§†é¢‘è¢«é€†æ—¶é’ˆæ—‹è½¬äº†90åº¦ï¼Œéœ€è¦é¡ºæ—¶é’ˆæ—‹è½¬å›æ¥```bash**é€‚ç”¨åœºæ™¯**ï¼šè§†é¢‘æœ¬èº«æ˜¯æ—‹è½¬çš„ï¼Œéœ€è¦åœ¨æ£€æµ‹å‰è‡ªåŠ¨çº æ­£### æ–¹æ¡ˆ1ï¼šä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°è‡ªåŠ¨æ—‹è½¬ï¼ˆæ¨èï¼‰â­## è§£å†³æ–¹æ¡ˆ---```                â†•ï¸æ—‹è½¬90åº¦:      ğŸš—  (ç«–å‘è½¦è¾†ï¼Œæ¨¡å‹ä»æœªè§è¿‡)æ­£å¸¸è®­ç»ƒæ•°æ®:  ğŸš— ğŸš™ ğŸš•  (æ¨ªå‘è½¦è¾†)```æ—‹è½¬90åº¦åï¼Œè½¦è¾†å½¢çŠ¶ã€é•¿å®½æ¯”ã€ç‰¹å¾å®Œå…¨ä¸åŒ¹é…ï¼Œæ¨¡å‹æ— æ³•è¯†åˆ«ã€‚- ä»æœªè§è¿‡**ç«–ç›´æ–¹å‘**çš„è½¦è¾†ï¼ˆæ—‹è½¬90åº¦ï¼‰- åªè§è¿‡**æ°´å¹³æ–¹å‘**çš„è½¦è¾†ï¼ˆæ­£å¸¸è¡Œé©¶è§†è§’ï¼‰YOLOv8é¢„è®­ç»ƒæ¨¡å‹ï¼ˆCOCOæ•°æ®é›†ï¼‰è®­ç»ƒæ—¶ï¼š### åŸå› **æ—‹è½¬90åº¦åYOLOv8æ— æ³•è¯†åˆ«è½¦è¾† - è¿™æ˜¯æ­£å¸¸ç°è±¡ï¼**
ç‰¹ç‚¹ï¼š
1. é”®ç›˜å®æ—¶æ§åˆ¶ä¿¡å·ç¯çŠ¶æ€
2. æˆ–ä½¿ç”¨æ—¶é—´è½´é…ç½®æ–‡ä»¶
3. ä¸éœ€è¦è½¦ç‰Œè¯†åˆ«
4. ä½¿ç”¨è½¦è¾†è¿½è¸ªIDä½œä¸ºå”¯ä¸€æ ‡è¯†
"""

import cv2
import time
import argparse
from pathlib import Path
import json

from core.vehicle_tracker import VehicleTracker
from core.violation_detector import ViolationDetector
from manual_signal_controller import ManualSignalController


class TrafficViolationPipelineManual:
    """æ‰‹åŠ¨æ§åˆ¶ç‰ˆæœ¬çš„äº¤é€šè¿è§„æ£€æµ‹ç®¡é“"""

    def __init__(
        self,
        rois_path: str,
        model_path: str = "yolov8s.pt",
        screenshot_dir: str = "./violations",
        signal_config: str = None,
        default_signal: str = "red",  # æ”¹ä¸ºé»˜è®¤çº¢ç¯ï¼Œæ–¹ä¾¿æµ‹è¯•é—¯çº¢ç¯
        rotation_angle: int = 0  # è§†é¢‘æ—‹è½¬è§’åº¦ (0, 90, -90, 180)
    ):
        """
        åˆå§‹åŒ–æ£€æµ‹ç®¡é“

        Args:
            rois_path: ROIé…ç½®æ–‡ä»¶è·¯å¾„
            model_path: YOLOv8æ¨¡å‹è·¯å¾„
            screenshot_dir: è¿è§„æˆªå›¾ä¿å­˜ç›®å½•
            signal_config: ä¿¡å·ç¯æ—¶é—´è½´é…ç½®æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
            default_signal: é»˜è®¤ä¿¡å·ç¯çŠ¶æ€
            rotation_angle: è§†é¢‘æ—‹è½¬è§’åº¦ï¼Œç”¨äºä¿®æ­£æ—‹è½¬çš„è§†é¢‘ (0, 90, -90, 180, 270)
        """
        print("ğŸš€ åˆå§‹åŒ–äº¤é€šè¿è§„æ£€æµ‹ç®¡é“ï¼ˆæ‰‹åŠ¨æ§åˆ¶ç‰ˆæœ¬ï¼‰...")
        print("=" * 60)

        # è§†é¢‘æ—‹è½¬è§’åº¦
        self.rotation_angle = rotation_angle
        if rotation_angle != 0:
            print(f"ğŸ”„ è§†é¢‘å°†è‡ªåŠ¨æ—‹è½¬ {rotation_angle}Â° åå†æ£€æµ‹")
        
        # 1. åˆå§‹åŒ–è½¦è¾†è¿½è¸ªå™¨ï¼ˆé™ä½ç½®ä¿¡åº¦å‡å°‘æ¼æ£€ï¼‰
        self.tracker = VehicleTracker(model_path=model_path, conf_threshold=0.25)

        # 2. åˆå§‹åŒ–è¿è§„æ£€æµ‹å™¨
        self.violation_detector = ViolationDetector(
            rois_path=rois_path,
            screenshot_dir=screenshot_dir
        )

        # 3. åˆå§‹åŒ–æ‰‹åŠ¨ä¿¡å·ç¯æ§åˆ¶å™¨
        self.signal_controller = ManualSignalController(
            config_path=signal_config,
            default_state=default_signal
        )

        print("=" * 60)
        print("æ‰€æœ‰æ¨¡å—åˆå§‹åŒ–å®Œæˆï¼\n")

        # æ‰“å°æ§åˆ¶è¯´æ˜
        self.signal_controller.print_controls()

    def process_video(self, video_path: str, output_path: str = None, display: bool = True):
        """
        å¤„ç†è§†é¢‘æ–‡ä»¶

        Args:
            video_path: è¾“å…¥è§†é¢‘è·¯å¾„
            output_path: è¾“å‡ºè§†é¢‘è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            display: æ˜¯å¦å®æ—¶æ˜¾ç¤º
        """
        print(f"ğŸ“¹ å¼€å§‹å¤„ç†è§†é¢‘: {video_path}")

        # æ‰“å¼€è§†é¢‘
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print(f"æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
            return

        # è·å–è§†é¢‘ä¿¡æ¯
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        if fps == 0:
            fps = 30  # é»˜è®¤å¸§ç‡
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        print(f"  åˆ†è¾¨ç‡: {width}x{height}")
        print(f"  å¸§ç‡: {fps} FPS")
        print(f"  æ€»å¸§æ•°: {total_frames}")

        # åˆ›å»ºè§†é¢‘å†™å…¥å™¨ï¼ˆå¦‚æœéœ€è¦ä¿å­˜ï¼‰
        writer = None
        if output_path:
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
            print(f"  è¾“å‡ºè§†é¢‘: {output_path}")

        print("\nğŸ¬ å¼€å§‹å¤„ç†...\n")

        frame_count = 0
        start_time = time.time()
        video_start_time = time.time()

        while True:
            ret, frame = cap.read()
            if not ret:
                break

            # å¦‚æœéœ€è¦æ—‹è½¬è§†é¢‘
            if self.rotation_angle != 0:
                if self.rotation_angle == 90 or self.rotation_angle == -270:
                    frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)
                elif self.rotation_angle == -90 or self.rotation_angle == 270:
                    frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)
                elif self.rotation_angle == 180 or self.rotation_angle == -180:
                    frame = cv2.rotate(frame, cv2.ROTATE_180)

            frame_count += 1
            current_time = time.time()

            # è®¡ç®—è§†é¢‘æ—¶é—´ï¼ˆç”¨äºæ—¶é—´è½´é…ç½®ï¼‰
            video_time = (frame_count - 1) / fps

            # ========== 1. è½¦è¾†æ£€æµ‹ä¸è¿½è¸ª ==========
            detections = self.tracker.detect_and_track(frame)

            # ========== 2. è·å–ä¿¡å·ç¯çŠ¶æ€ ==========
            # å¦‚æœæœ‰æ—¶é—´è½´é…ç½®ï¼Œæ ¹æ®è§†é¢‘æ—¶é—´è·å–
            # å¦åˆ™ä½¿ç”¨æ‰‹åŠ¨è®¾ç½®çš„çŠ¶æ€
            signal_states = self.signal_controller.get_signal_states(video_time)
            left_turn_signals = self.signal_controller.get_left_turn_signals(video_time)

            # æ›´æ–°è¿è§„æ£€æµ‹å™¨çš„ä¿¡å·ç¯çŠ¶æ€
            for direction, state in signal_states.items():
                self.violation_detector.traffic_lights[direction] = state
            
            # æ›´æ–°å·¦è½¬ä¿¡å·ç¯çŠ¶æ€
            for direction, state in left_turn_signals.items():
                self.violation_detector.left_turn_signals[direction] = state

            # ========== 3. è¿è§„æ£€æµ‹ ==========
            violations = self.violation_detector.process_frame(
                frame, detections, current_time
            )

            # ========== 4. å¯è§†åŒ– ==========
            vis_frame = self._visualize(frame, detections, signal_states, left_turn_signals, violations, video_time)

            # ä¿å­˜è¾“å‡ºè§†é¢‘
            if writer:
                writer.write(vis_frame)

            # å®æ—¶æ˜¾ç¤º
            if display:
                cv2.imshow("Traffic Violation Detection [æŒ‰Qé€€å‡º]", vis_frame)
                key = cv2.waitKey(1) & 0xFF

                # å¤„ç†é”®ç›˜è¾“å…¥
                if key == ord('q'):
                    print("\nâ¸ï¸ ç”¨æˆ·ä¸­æ–­")
                    break
                else:
                    # å°è¯•å¤„ç†ä¿¡å·ç¯æ§åˆ¶é”®
                    self.signal_controller.handle_keyboard(key)

            # è¿›åº¦æ˜¾ç¤º
            if frame_count % 30 == 0 or frame_count == 1:
                elapsed = time.time() - start_time
                fps_actual = frame_count / elapsed if elapsed > 0 else 0
                progress = (frame_count / total_frames) * 100 if total_frames > 0 else 0
                print(f"  å¤„ç†è¿›åº¦: {frame_count}/{total_frames} ({progress:.1f}%) | "
                      f"FPS: {fps_actual:.1f} | è¿è§„: {len(self.violation_detector.violations)}")

        # æ¸…ç†
        cap.release()
        if writer:
            writer.release()
        cv2.destroyAllWindows()

        # ç»Ÿè®¡ç»“æœ
        elapsed_time = time.time() - start_time
        print("\n" + "=" * 60)
        print("å¤„ç†å®Œæˆï¼")
        print("=" * 60)
        print(f"  æ€»å¸§æ•°: {frame_count}")
        print(f"  å¤„ç†æ—¶é—´: {elapsed_time:.2f}ç§’")
        print(f"  å¹³å‡FPS: {frame_count / elapsed_time:.2f}")
        print(f"\nè¿è§„ç»Ÿè®¡:")

        summary = self.violation_detector.get_violation_summary()
        print(f"   æ€»è¿è§„æ•°: {summary['total_violations']}")
        print(f"    - é—¯çº¢ç¯: {summary['red_light_running']}")
        print(f"    - é€†è¡Œ: {summary['wrong_way_driving']}")
        print(f"    - è·¨å®çº¿å˜é“: {summary['lane_change_across_solid_line']}")
        print(f"    - çº¢ç¯è¿›å…¥å¾…è½¬åŒº: {summary['waiting_area_red_entry']}")
        print(f"    - éæ³•é©¶ç¦»å¾…è½¬åŒº: {summary['waiting_area_illegal_exit']}")

        # å¯¼å‡ºè¿è§„è®°å½•ï¼ˆä¿å­˜åˆ°violationsæ–‡ä»¶å¤¹ï¼‰
        violations_dir = Path("./violations")
        violations_dir.mkdir(exist_ok=True)  # ç¡®ä¿æ–‡ä»¶å¤¹å­˜åœ¨
        violation_json = violations_dir / (str(Path(video_path).stem) + "_violations.json")
        self.violation_detector.export_violations(str(violation_json))

        return summary

    def _visualize(self, frame, detections, signal_states, left_turn_signals, violations, video_time):
        """
        å¯è§†åŒ–æ£€æµ‹ç»“æœ

        Args:
            frame: åŸå§‹å¸§
            detections: è½¦è¾†æ£€æµ‹ç»“æœ
            signal_states: ä¿¡å·ç¯çŠ¶æ€
            left_turn_signals: å·¦è½¬ä¿¡å·ç¯çŠ¶æ€
            violations: æœ¬å¸§è¿è§„åˆ—è¡¨
            video_time: è§†é¢‘æ—¶é—´ï¼ˆç§’ï¼‰

        Returns:
            å¯è§†åŒ–åçš„å¸§
        """
        vis_frame = frame.copy()

        # 1. ç»˜åˆ¶è½¦è¾†æ£€æµ‹æ¡†å’Œè½¨è¿¹
        vis_frame = self.tracker.draw_detections(vis_frame, detections)

        # 2. ç»˜åˆ¶ä¿¡å·ç¯çŠ¶æ€é¢æ¿
        self._draw_signal_panel(vis_frame, signal_states, left_turn_signals)

        # 3. ç»˜åˆ¶è¿è§„è­¦å‘Š
        if violations:
            cv2.putText(
                vis_frame, f"!!! VIOLATION DETECTED !!! Count: {len(violations)}",
                (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 3
            )

        # 4. ç»˜åˆ¶ç»Ÿè®¡ä¿¡æ¯
        self._draw_statistics(vis_frame, video_time)

        # 5. ç»˜åˆ¶æ§åˆ¶æç¤º
        self._draw_controls_hint(vis_frame)

        return vis_frame

    def _draw_signal_panel(self, frame, signal_states, left_turn_signals):
        """ç»˜åˆ¶ä¿¡å·ç¯çŠ¶æ€é¢æ¿ï¼ˆå³ä¸Šè§’ï¼‰"""
        panel_x = frame.shape[1] - 350
        panel_y = 30

        # æ ‡é¢˜
        cv2.putText(
            frame, "Signal Lights:", (panel_x, panel_y),
            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2
        )

        # å„æ–¹å‘çŠ¶æ€
        y_offset = panel_y + 30
        direction_names = {
            'north_bound': 'North',
            'south_bound': 'South',
            'west_bound': 'West',
            'east_bound': 'East'
        }

        for direction, state in signal_states.items():
            color = (0, 255, 0) if state == 'green' else (0, 0, 255)
            
            # ç›´è¡Œç¯
            text = f"{direction_names[direction]}: {state.upper()}"
            cv2.putText(
                frame, text, (panel_x, y_offset),
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2
            )
            
            # å·¦è½¬ç¯ï¼ˆæ˜¾ç¤ºåœ¨åŒä¸€è¡Œï¼‰
            left_state = left_turn_signals.get(direction, 'red')
            left_color = (0, 255, 0) if left_state == 'green' else (0, 0, 255)
            left_text = f"L:{left_state[:1].upper()}"
            cv2.putText(
                frame, left_text, (panel_x + 200, y_offset),
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, left_color, 2
            )
            
            y_offset += 25

    def _draw_statistics(self, frame, video_time):
        """ç»˜åˆ¶ç»Ÿè®¡ä¿¡æ¯ï¼ˆåº•éƒ¨ï¼‰"""
        summary = self.violation_detector.get_violation_summary()
        y_offset = frame.shape[0] - 60

        stats_text = f"Time: {video_time:.1f}s | Violations: {summary['total_violations']} " \
                     f"(Red: {summary['red_light_running']} | Wrong Way: {summary['wrong_way_driving']} | Lane Change: {summary['lane_change_across_solid_line']})"

        # èƒŒæ™¯
        cv2.rectangle(frame, (0, y_offset - 35), (frame.shape[1], frame.shape[0]), (0, 0, 0), -1)

        cv2.putText(
            frame, stats_text, (10, y_offset),
            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2
        )

    def _draw_controls_hint(self, frame):
        """ç»˜åˆ¶æ§åˆ¶æç¤ºï¼ˆå·¦ä¸‹è§’ï¼‰"""
        hints = [
            "Controls: [1-4]Signal [5-6]LeftTurn All [7-0]LeftTurn N/S/W/E [Q]Quit"
        ]

        y_offset = frame.shape[0] - 90

        for hint in hints:
            cv2.putText(
                frame, hint, (10, y_offset),
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1
            )
            y_offset += 20


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="TrafficMind - äº¤é€šè¿è§„æ£€æµ‹ç³»ç»Ÿï¼ˆæ‰‹åŠ¨æ§åˆ¶ç‰ˆæœ¬ï¼‰")
    parser.add_argument("--video", type=str, required=True, help="è¾“å…¥è§†é¢‘è·¯å¾„")
    parser.add_argument("--rois", type=str, default="./data/rois.json", help="ROIé…ç½®æ–‡ä»¶")
    parser.add_argument("--model", type=str, default="yolov8s.pt", help="YOLOv8æ¨¡å‹è·¯å¾„ï¼ˆé»˜è®¤yolov8s.ptï¼Œé€Ÿåº¦æ›´å¿«ï¼‰")
    parser.add_argument("--output", type=str, default=None, help="è¾“å‡ºè§†é¢‘è·¯å¾„")
    parser.add_argument("--no-display", action="store_true", help="ä¸å®æ—¶æ˜¾ç¤º")
    parser.add_argument("--rotation", type=int, default=0, 
                       choices=[0, 90, -90, 180, 270, -270],
                       help="è§†é¢‘æ—‹è½¬è§’åº¦ (90=é¡ºæ—¶é’ˆ90Â°, -90=é€†æ—¶é’ˆ90Â°)")
    parser.add_argument("--signal-config", type=str, default=None, help="ä¿¡å·ç¯æ—¶é—´è½´é…ç½®æ–‡ä»¶")
    parser.add_argument("--default-signal", type=str, default="red",  # æ”¹ä¸ºé»˜è®¤çº¢ç¯
                       choices=['red', 'green', 'yellow'], help="é»˜è®¤ä¿¡å·ç¯çŠ¶æ€")

    args = parser.parse_args()

    # åˆ›å»ºç®¡é“
    pipeline = TrafficViolationPipelineManual(
        rois_path=args.rois,
        model_path=args.model,
        signal_config=args.signal_config,
        default_signal=args.default_signal,
        rotation_angle=args.rotation
    )

    # å¤„ç†è§†é¢‘
    pipeline.process_video(
        video_path=args.video,
        output_path=args.output,
        display=not args.no_display
    )


if __name__ == "__main__":
    main()
